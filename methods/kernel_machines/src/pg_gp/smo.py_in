#!/usr/bin/env python

import plpy
import math
from time import clock, time

def __validate_input_table(input_table, id_col, feature_col, dependent_col) :
    """
    Assert the name of the input table should not be None, and
    the dimension of the column "ind" should be less than or equal to 102, 400.

    @param input_table Name of table/view containing the training data
    """
    rv = plpy.execute("""
                        SELECT array_upper({0}, 1) as dim, {1}, {2} 
                        FROM {3} LIMIT 1
                      """.format(feature_col,id_col,dependent_col,input_table));
    if rv.nrows() == 0 :
        plpy.error("the training table is empty");

    if rv is not None and rv[0]["dim"] > 102400:
        plpy.error("the maximum number of features is 102400");

def __get_kernel_func(schema_madlib, func_name, degree, gamma):
    if func_name=='polynomial':
        return schema_madlib+'.svm_polynomial({x1},{x2},'+str(degree)+')'
    elif func_name=='linear':
        return schema_madlib+'.svm_dot({x1},{x2})'
    elif func_name=='gaussian':
        return schema_madlib+'.svm_gaussian({x1},{x2},'+str(gamma)+')'
    else:
        plpy.error("Invalid kernel function specified")


# -----------------------------------------------
# Function to run the classification algorithm
# -----------------------------------------------
def train(schema_madlib, input_table , id_col , feature_col , dependent_col , model_table ,  kernel_func, C, threshold, degree, gamma, max_iter, verbosity):
    """
    Executes the support vector classification algorithm.

    @param input_table Name of table/view containing the training data
    @param model_table Name under which we want to store the learned model
    @param parallel A flag indicating whether the system should learn multiple models in parallel
    @param kernel_func Kernel function
    @param verbose Verbosity of reporting
    @param eta Learning rate in (0,1] (default value is 0.1)
    @param nu Compression parameter in (0,1] associated with the fraction of training data that will become support vectors (default value is 0.005)

    """

    # Output error if model_table already exist
    # if __check_rel_exist(model_table):
    #    plpy.error('Table ' + model_table + ' exists; please use a different model table or drop ' + model_table + ' before calling this function.');
    # plpy.execute('drop table if exists ' + model_table);

    __validate_input_table(input_table, id_col, feature_col, dependent_col);
    eps = 1e-10
    k_func = __get_kernel_func(schema_madlib, kernel_func, degree, gamma)

    plpy.execute('DROP TABLE IF EXISTS smo_train_temp')
    plpy.execute("""
                    CREATE TEMP TABLE smo_train_temp AS 
                    SELECT {id_col} id, {feature_col} feature, {dependent_col} dependent_val, 
                           0.0::float8 AS alpha, -{dependent_col} AS f
                    FROM {src_table}
                 """.format(id_col = id_col, feature_col = feature_col, 
                            dependent_col = dependent_col, src_table=input_table)
                 )
    plpy.execute('DROP TABLE IF EXISTS smo_train_temp2')
    plpy.execute("CREATE TEMP TABLE smo_train_temp2 (LIKE smo_train_temp)")

    src_table = 'smo_train_temp'
    dst_table = 'smo_train_temp2'
    plpy.execute("DROP TABLE IF EXISTS smo_train_iteration")
    plpy.execute("""
        CREATE TEMP TABLE smo_train_iteration AS
            SELECT 0::float8 b_low, 0::float8 alpha_low, 
                   0::int i_low, 0::float8 y_low, 
                   null::float8[] x_low,
                   0::float8 b_up, 0::float8 alpha_up, 
                   0::int i_up, 0::float8 y_up, 
                   null::float8[] x_up,
                   0.0::float8 alpha_low_new, 0.0::float8 alpha_up_new
            DISTRIBUTED randomly
                   """)
    dual = 0.0
    iter = 0
    scan_all = True
    scan_all_next = True
    while iter<max_iter:
        iter = iter+1
        scan_all = scan_all_next
        if not scan_all:
            where_cond = 'WHERE alpha>0 AND alpha<{C}'.format(C=C)
        else:
            where_cond = ''
        start = time()
        plpy.execute("DROP TABLE IF EXISTS b_temp_table")
        query ="""
            CREATE TEMP TABLE b_temp_table
                AS
                SELECT max( CASE WHEN ((alpha>0 AND alpha<{C}) OR 
                                              (alpha={C} AND dependent_val>0) OR
                                              (alpha=0 AND dependent_val<0)) THEN
                                        f
                                   ELSE
                                        -'infinity'::float8
                                   END
                            ) as b_low,
                        min( CASE WHEN ((alpha>0 AND alpha<{C}) OR 
                                              (alpha={C} AND dependent_val<0) OR
                                              (alpha=0 AND dependent_val>0)) THEN
                                        f
                                   ELSE
                                        'infinity'::float8
                                   END
                            ) as b_up
                FROM {src_table}
                {where_cond}
                """.format( C = C, where_cond = where_cond, src_table = src_table )
        plpy.execute(query)
        if verbosity>0:
            plpy.info(query)
            plpy.info('Find alpha time in iteration {0}: {1}'.format(iter, time()-start))

        start = time()

        if scan_all:
            where_cond_low = """
                        ((alpha>0 AND alpha<{C}) OR 
                                (alpha={C} AND dependent_val>0) OR
                                (alpha=0 AND dependent_val<0))""".format(C=C)
        else:
            where_cond_low = """ (alpha>0 AND alpha<{C})""".format(C=C)

        if scan_all:
            where_cond_up = """
                        ((alpha>0 AND alpha<{C}) OR 
                                (alpha={C} AND dependent_val<0) OR
                                (alpha=0 AND dependent_val>0))""".format(C=C)
        else:
            where_cond_up = """ (alpha>0 AND alpha<{C})""".format(C=C)
        
        plpy.execute('DROP TABLE IF EXISTS smo_up_low_table')

        query = """
                CREATE TEMP TABLE smo_up_low_table
                    AS
                    SELECT s.f, s.alpha, s.id, s.dependent_val, s.feature,
                           b.b_low, b.b_up
                    FROM  b_temp_table b  CROSS JOIN {src_table} s
                    WHERE 
                          (
                            (s.f = b.b_low AND {where_cond_low})
                                OR
                            (s.f = b.b_up AND {where_cond_up})
                          )
                 """.format(where_cond_low = where_cond_low,
                                where_cond_up = where_cond_up,
                                src_table = src_table)

        plpy.execute(query)

        if verbosity>0:
            plpy.info(query)
            plpy.info('Construct up/low table time in iteration {0}: {1}'.format(iter, time()-start))

        start = time()
        plpy.execute("DROP TABLE IF EXISTS smo_train_iteration")
        query = """
                    CREATE TEMP TABLE smo_train_iteration AS
                    SELECT
                        *,
                        0.0::float8 alpha_low_new,
                        0.0::float8 alpha_up_new
                    FROM
                    (
                        SELECT
                            l.b_up AS b_up,
                            l.alpha AS alpha_up,
                            l.id AS i_up,
                            l.dependent_val AS y_up,
                            l.feature AS x_up
                        FROM smo_up_low_table l
                        WHERE f=b_up LIMIT 1
                    ) l 
                    CROSS JOIN 
                    (
                        SELECT
                            l.b_low AS b_low,
                            l.alpha AS alpha_low,
                            l.id AS i_low,
                            l.dependent_val AS y_low,
                            l.feature AS x_low
                        FROM smo_up_low_table l
                        WHERE f=b_low LIMIT 1
                    ) t
                    """
        plpy.execute(query)

        if verbosity>0:
            plpy.info(query)
            plpy.info('Store alpha time in iteration {0}: {1}'.format(iter, time()-start))

        start = time()
        rv = plpy.execute('SELECT *,'+k_func.format(x1='x_low', x2='x_low')\
                          +'+'+k_func.format(x1='x_up', x2='x_up')+'-2*'\
                          +k_func.format(x1='x_low', x2='x_up') +""" AS deri 
                           FROM smo_train_iteration
                          """)

        y_low = rv[0]['y_low']
        y_up = rv[0]['y_up']
        x_up = rv[0]['x_up']
        x_low = rv[0]['x_low']
        b_low = rv[0]['b_low']
        b_up = rv[0]['b_up']
        alpha_low = rv[0]['alpha_low']
        alpha_up = rv[0]['alpha_up']
        i_low = rv[0]['i_low']
        i_up  = rv[0]['i_up']
        deri = rv[0]['deri']
        if verbosity>0:
            plpy.info("""
                    after get alpha from table. deri:{0},alpha_low:{1},alpha_up:{2},
                    i_low:{3},i_up:{4},
                    x_low:{5}, 
                    x_up:{6},
                    y_low:{7},
                    y_up:{8}
                    """.format(deri, alpha_low, alpha_up,i_low,i_up, x_low, x_up,y_low,y_up));

        if (b_low-b_up<threshold):
            if scan_all:
                break
            else:
                scal_all_next = True
                continue
        else:
            scal_all_next = False
            if verbosity>0:
                plpy.info('b_low-b_up: {0}, threshold:{1}, b_low:{2}, b_up:{3}'.format(b_low-b_up, threshold, b_low, b_up))
            
        if (y_low != y_up):
            L_low = max(0, alpha_low-alpha_up)
            H_low = min(C, C+alpha_low-alpha_up)
        else:
            L_low = max(0, alpha_low+alpha_up-C)
            H_low = min(C, alpha_low+alpha_up)
        
        if L_low>H_low:
            if scan_all:
                plpy.warning('invalid number. L_low: {0}, H_low:{1}'.format(L_low, H_low))                
                break
            else:
                scal_all_next = True
                continue

        if (deri>0):
            alpha_low_new = alpha_low+y_low*(b_up-b_low)/deri
        elif (y_low*(b_up-b_low)>0):
            alpha_low_new = H_low
        else:
            alpha_low_new = L_low

        if verbosity>0:
            plpy.info('before clip, alpha_low_new: {0}'.format(alpha_low_new))

        if (alpha_low_new>H_low):
            alpha_low_new = H_low
        elif (alpha_low_new<L_low):
            alpha_low_new = L_low

        if verbosity>0:
            plpy.info('after clip, alpha_low_new: {0}, H_low:{1}, L_low:{2}'.format(alpha_low_new, H_low, L_low))
        
        if abs(alpha_low_new-alpha_low)<eps*(alpha_low_new+alpha_low+eps):
            plpy.warning('too small alpha change. alpha_low_new: {0}, alpha_low:{1}'.format(alpha_low_new, alpha_low))
            break

        alpha_up_new = alpha_up+y_low*y_up*(alpha_low-alpha_low_new)

        if verbosity>0:
            plpy.info('Compute new alpha time in iteration {0}: {1}'.format(iter, time()-start))
            
        start = time()
        dual = dual - (alpha_up_new-alpha_up)*(b_up-b_low)/y_up-deri*pow((alpha_up_new-alpha_up)/y_up, 2)/2
        plpy.execute("""
                     UPDATE smo_train_iteration
                     SET alpha_low_new={alpha_low_new},
                         alpha_up_new={alpha_up_new}
                      """.format(alpha_low_new=str(alpha_low_new),
                                 alpha_up_new=str(alpha_up_new))
                      )
        
        #plpy.execute('ANALYZE smo_train_temp')
        #plpy.execute('ANALYZE smo_train_iteration')
        
        plpy.execute('TRUNCATE {dst_table}'.format(dst_table = dst_table))
        plpy.execute(("""
                     INSERT INTO {dst_table}
                        SELECT id, feature, dependent_val,
                                CASE WHEN(t.id=l.i_low) THEN
                                    alpha_low_new
                                ELSE
                                    CASE WHEN(t.id=l.i_up) THEN
                                        alpha_up_new
                                    ELSE
                                        alpha
                                    END
                                END AS alpha, 
                                f+(alpha_low_new-alpha_low)*y_low*"""+k_func.format(x1='x_low',x2='feature')+"""
                                +(alpha_up_new-alpha_up)*y_up*"""+k_func.format(x1='x_up',x2='feature') +""" AS f
                        FROM
                        smo_train_iteration l CROSS JOIN {src_table} t
                      """).format(src_table=str(src_table),
                                 dst_table=str(dst_table))
                      )
        temp_str = src_table
        src_table = dst_table
        dst_table = temp_str

        if verbosity>0:
            plpy.info('Update f time in iteration {0}: {1}'.format(iter, time()-start))

        start = time()

        rv =  plpy.execute("""
                            SELECT avg(f) b
                            FROM {src_table}
                            WHERE alpha>0 and alpha<{C}
                            """.format(C = str(C), src_table=src_table))

        b = rv[0]['b']
        
        if b is None:
            continue
        
        rv = plpy.execute("""
                          SELECT sum(
                                    CASE WHEN(dependent_val>0) THEN
                                        alpha*dependent_val*f+{C}*{schema_madlib}.array_max(array[0, {b}-f])
                                    ELSE
                                        alpha*dependent_val*f+{C}*{schema_madlib}.array_max(array[0, -({b})+f])
                                    END
                                    ) AS gap
                          FROM
                          {src_table}
                          """.format( C =str(C), schema_madlib=schema_madlib, b=str(b),src_table=src_table )
                          )
        duality_gap = rv[0]['gap']

        if verbosity>0:
            plpy.info('duality gap time in iteration {0}: {1}'.format(iter, time()-start))

        if (duality_gap<threshold*dual):
            break
        else:
            if verbosity>0:
                plpy.info('duality_gap: {0}, threshold:{1}, dual:{2}, ratio:{3}'.format(duality_gap, threshold, dual, duality_gap/dual))

    plpy.execute('drop table if exists ' + model_table);
    plpy.execute("""
                CREATE TABLE {model} AS
                    SELECT feature x, dependent_val y, alpha, 
                           CASE WHEN(alpha>0 AND alpha<{C}) THEN
                                f 
                           ELSE
                                null
                           END AS b
                    FROM smo_train_temp
                    WHERE alpha>0
                """.format(model=model_table, C=str(C)))


# ---------------------------------------------------
# Function to predict the labels of points in a table
# ---------------------------------------------------
def classify(schema_madlib, input_table, data_col, id_col, model_table, output_table, kernel_func, degree, gamma):
    """
    Scores the data points stored in a table using a learned support vector model.

    @param input_table Name of table/view containing the data points to be scored
    @param data_col Name of column in input_table containing the data points
    @param id_col Name of column in input_table containing (integer) identifier for data point
    @param model_table Name of learned model
    @param output_table Name of table to store the results
    @param parallel A flag indicating whether the system should learn multiple models in parallel

    """

    k_func = __get_kernel_func(schema_madlib, kernel_func, degree, gamma)

    plpy.execute('drop table if exists ' + output_table);
    plpy.execute('create table ' + output_table + ' ( id int, prediction float8 ) m4_ifdef(`__GREENPLUM__', `distributed by (id)')');

    plpy.execute(("""
                INSERT INTO {0}
                    SELECT {1},
                           sum(m.alpha*m.y*"""+k_func.format(x1='m.x',x2=data_col)+""")
                           -coalesce(avg(m.b), 0)
                    FROM {2} m CROSS JOIN {3} t
                    GROUP BY {4}
                """).format(output_table, id_col, 
                           model_table, input_table, id_col)
                )

